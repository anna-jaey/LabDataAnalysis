[
  {
    "objectID": "qPCR.html",
    "href": "qPCR.html",
    "title": "qPCR Data Analysis",
    "section": "",
    "text": "qPCR\nin progress"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wet lab data analysis",
    "section": "",
    "text": "Welcome\nThis site provides example analysis workflows for commonly used assays in the biological wet lab. Originally created for my students, I’m sharing it here so others can benefit as well. It’s a work in progress.\nEach section walks through the key steps of data analysis, from raw data to final results, highlighting important quality control measures and potential pitfalls.The focus is on understanding the logic of data analysis and providing a starting point that can be adapted to different experiments. The workflows are written in R, feel free to use and modify the code :) However, you should be able to follow and adapt, whether or not you use R.\n\n\nGeneral Steps\n\nInspect raw data & perform QC\n\nIs the data within the expected range?\nAre there any obvious outliers?\nAn empty well due to a pipetting mistake should be immediately visible\n\nIdentify and handle outliers\n\nDo you have a valid reason to exclude a data point?\nUse lab notes or experimental context to justify exclusions.\n\nPerform necessary preprocessing\n\nBackground subtraction, normalisation\nIs it necessary for your data?\nWhy and how should it be done?\n\nGraph your data meaningfully\n\nConsider who your are showing your results to (colleague, final report, publication)\nSelect a meaningful graph type that fits your data\nMake clear what you show: pipetting replicates vs. biological replicates, how many replicates?\nAxis labels, clear legends and annotations\n\nStatistical analysis: Are differences meaningful?\n\nDescriptive stats: Mean, standard deviation, confidence intervals\nHypothesis testing: t-tests, ANOVA, non-parametric tests—which is appropriate?\n\nMultiple comparisons: If comparing many groups, adjust for false positives (e.g., Bonferroni, Tukey)"
  },
  {
    "objectID": "colourimetric.html",
    "href": "colourimetric.html",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "This workflow is for experiments, where we don’t have a ‘standard curve’ or calibration curve, that is a serial dilution of known concentrations. Instead, we rely on relative comparisons between experimental groups.\n\n\nFirst, load the necessary libraries.\n\nlibrary(tidyverse)\n\n\n\n\nLoad the raw data:\n\ncolourimetric_df &lt;- read.csv(\"example_data/colorimetric_example_tidy.csv\")\n\nglimpse(colourimetric_df)\n\nRows: 45\nColumns: 4\n$ Experiment &lt;chr&gt; \"Exp1\", \"Exp1\", \"Exp1\", \"Exp1\", \"Exp1\", \"Exp1\", \"Exp1\", \"Ex…\n$ Group      &lt;chr&gt; \"Group1\", \"Group1\", \"Group1\", \"Group2\", \"Group2\", \"Group2\",…\n$ Replicate  &lt;int&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,…\n$ Absorbance &lt;dbl&gt; 0.6790, 0.6650, 0.6560, 0.5430, 0.5380, 0.5830, 0.7560, 0.7…\n\n\nThe example data set are absorbance values, the raw values from the plate reader. This example data set contains data for three different experiments, four treatment groups. For each experiment and each group there are three technical replicates (pipetting replicates). There is also three “blank” measurements for each group, that is the assay buffer without a sample. A “blank” is a control that contains all assay components except the analyte of interest (e.g. the buffer but no cells), used to measure background absorbance and correct for non-specific signal.\n\n\n\nsummary(colourimetric_df)\n\n  Experiment           Group             Replicate   Absorbance    \n Length:45          Length:45          Min.   :1   Min.   :0.0615  \n Class :character   Class :character   1st Qu.:1   1st Qu.:0.5380  \n Mode  :character   Mode  :character   Median :2   Median :0.6790  \n                                       Mean   :2   Mean   :0.5694  \n                                       3rd Qu.:3   3rd Qu.:0.7450  \n                                       Max.   :3   Max.   :0.9170  \n\n\nAny missing values should be examined to determine if they result from experimental errors. There are no missing values in the example data.\n\n\n\nTo see the distribution of absorbance values across different groups and experiments, plot:\n\nylimit &lt;- max(colourimetric_df$Absorbance)*1.1 # use the max absorbance value for upper y limit\nggplot(colourimetric_df, aes(x=Group, y=Absorbance, colour=Experiment, shape=as.factor(Replicate))) +\n  geom_point(position = position_dodge(0.5), alpha = 0.75, size = 2) +\n  stat_summary(aes(group = Experiment),\n               fun = mean,\n               fun.min = function(x) mean(x) - sd(x),\n               fun.max = function(x) mean(x) + sd(x),\n               geom = \"pointrange\", size = 1, shape = 18,\n               colour = 'darkgrey', alpha = 0.75,\n               position = position_dodge(0.3)) +\n  labs(color = 'Experiment', shape = 'Replicate', x=\"\") +\n  scale_y_continuous(limits = c(0, ylimit))+\n  theme_minimal(base_size = 12) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\nGraphing one point for each data point, using colours and shapes to distinguish between the experiments and the technical replicates. QC check: data falls within the linear range of the assay (in the example the linear range is between 0.1 and 1). However, there is one value certainly “off”.\n\n\n\n\nIn the graph above, we can see that Experiment 1, Group 3, Replicate 3 has an absorbance value similar to the blank readings. We have to determine if this is a real reading or if data collection errors such as pipetting mistakes have occurred. In the example, we confirm with our “lab notes” that this well might not have been properly pipetted, and we exclude it:\n\ncolourimetric_df &lt;- colourimetric_df %&gt;% \n  filter(!(Experiment == \"Exp1\" & Group == \"Group3\" & Replicate == 3))\n\nWe replot the data:\n\nylimit &lt;- max(colourimetric_df$Absorbance)*1.1 # use the max absorbance value for upper y limit\nggplot(colourimetric_df, aes(x=Group, y=Absorbance, colour=Experiment, shape=as.factor(Replicate))) +\n  geom_point(position = position_dodge(0.5), alpha = 0.75, size = 2) +\n  stat_summary(aes(group = Experiment),\n               fun = mean,\n               fun.min = function(x) mean(x) - sd(x),\n               fun.max = function(x) mean(x) + sd(x),\n               geom = \"pointrange\", size = 1, shape = 18,\n               colour = 'darkgrey', alpha = 0.75,\n               position = position_dodge(0.3)) +\n  labs(color = 'Experiment', shape = 'Replicate', x=\"\") +\n  scale_y_continuous(limits = c(0, ylimit))+\n  theme_minimal(base_size = 12) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\nand we see that the exclusion worked as expected. This outlier is removed based on documented lab notes confirming a technical issue. Excluding data without a valid reason is cherry-picking and is not scientifically sound.\n\n\n\n\n\nIt depends.\n\nIf you are interested in absolute absorbance values - yes.\nIf there is significant background noise and it is also different between the plates (experiments), it can better to subtract the mean blank value per experiment to correct for plate inconsistencies. However, if you see inconsistencies between plates that you wouldn’t expect, (there is no technical reason for it), you should check your experimental set-up.\nIf the blank values are consistently low, there is minimal drift, and you are interested in relative comparisons between groups (or interpolating agains standard curve), subtraction may not be necessary.\n\nFor the example, we can try both:\n\nblank_means &lt;- colourimetric_df %&gt;%\n  filter(Group == \"Blank\") %&gt;%\n  group_by(Experiment) %&gt;%\n  summarise(BlankMean = mean(Absorbance))\n\ncolourimetric_df &lt;- colourimetric_df %&gt;%\n  left_join(blank_means, by = \"Experiment\") %&gt;%\n  mutate(Absorbance_Corrected = Absorbance - BlankMean) %&gt;%\n  filter(Group != \"Blank\")  # Remove blank values now that we have subtracted\n\n\n\n\n\nEach experiment contains technical replicates, which we average to obtain a single value per group per experiment. As we try with and without subtracting the blank reading, we average both.\n\ncolourimetric_df_meantechnical &lt;- colourimetric_df %&gt;%  \n  group_by(Experiment, Group) %&gt;%\n  summarise(AbsorbanceMeanCorrected = mean(Absorbance_Corrected),\n            AbsorbanceSDCorrected = sd(Absorbance_Corrected),\n            AbsorbanceMean = mean(Absorbance),\n            AbsorbanceSD = sd(Absorbance)\n            )\n\n\n\n\nTo compare across experiments, we normalise all values relative to the control group (Group 1) within each experiment: As we try with and without subtracting the blank reading, we do it for both.\n\ncolourimetric_df_Normalised &lt;- colourimetric_df_meantechnical %&gt;%  \n  group_by(Experiment) %&gt;%\n  mutate(Normalised = AbsorbanceMean / AbsorbanceMean[Group == 'Group1'],\n         NormalisedCorrected = AbsorbanceMeanCorrected / AbsorbanceMeanCorrected[Group == 'Group1'])\n\n\n\n\nTo report results, we show the data point for each biological replicate as well as the mean and standard deviation.\nylimit &lt;- max(colourimetric_df_Normalised$Normalised)*1.1\nggplot(colourimetric_df_Normalised, aes(x=Group, y=Normalised)) +\n  geom_jitter(height = 0, alpha = 0.75, size = 2) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\", \n    position = position_dodge(0.3), \n    width = 0.6,\n    alpha = 0.5,\n    fill = 'grey30') +\n  stat_summary(\n    fun.min = function(x) mean(x) - sd(x), \n    fun.max = function(x) mean(x) + sd(x), \n    geom = \"errorbar\", \n    width = 0.2,\n    position = position_dodge(0.3),\n    colour = 'grey30',\n    alpha = 0.75) +\n  scale_y_continuous(limits = c(0, ylimit))+\n  labs(y='FC to Group 1', x=\"\")+\n  theme_minimal(base_size = 12) +\n  theme(legend.position = 'bottom')\n#ylimit &lt;- max(colourimetric_df_Normalised$NormalisedCorrected)*1.1\nggplot(colourimetric_df_Normalised, aes(x=Group, y=NormalisedCorrected)) +\n  geom_jitter(height = 0, alpha = 0.75, size = 2) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\", \n    position = position_dodge(0.3), \n    width = 0.6,\n    alpha = 0.5,\n    fill = 'grey30') +\n  stat_summary(\n    fun.min = function(x) mean(x) - sd(x), \n    fun.max = function(x) mean(x) + sd(x), \n    geom = \"errorbar\", \n    width = 0.2,\n    position = position_dodge(0.3),\n    colour = 'grey30',\n    alpha = 0.75) +\n  scale_y_continuous(limits = c(0, ylimit))+\n  labs(y='FC to Group 1',  x=\"\")+\n  theme_minimal(base_size = 12) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nAbsorbance value fold change (FC) to Group 1\n\n\n\n\n\n\n\nAbsorbance value fold change (FC) to Group 1 after subtracting the blank reading\n\n\n\n\n\nThe graph above displays the fold change relative to Group 1. Key observations: - Since Group 1 is the normalisation reference for each experiment, the mean value is always 1, and the standard deviation is 0, - When fold changes are less than 1, a standard y-axis can be misleading. Consider using a log2 transformation for clearer visualisation.\nggplot(colourimetric_df_Normalised, aes(x=Group, y=log2(Normalised))) +\n  geom_jitter(height = 0, alpha = 0.75, size = 2) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\", \n    position = position_dodge(0.3), \n    width = 0.6,\n    alpha = 0.5,\n    fill = 'grey30') +\n  stat_summary(\n    fun.min = function(x) mean(x) - sd(x), \n    fun.max = function(x) mean(x) + sd(x), \n    geom = \"errorbar\", \n    width = 0.2,\n    position = position_dodge(0.3),\n    colour = 'grey30',\n    alpha = 0.75) +\n  labs(y='log2 FC to Group 1')+\n  theme_minimal() +\n  theme(legend.position = 'bottom')\nylimit &lt;- max(colourimetric_df_Normalised$AbsorbanceMeanCorrected)*1.1\nggplot(colourimetric_df_Normalised, aes(x=Group, y=log2(NormalisedCorrected))) +\n  geom_jitter(height = 0, alpha = 0.75, size = 2) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\", \n    position = position_dodge(0.3), \n    width = 0.6,\n    alpha = 0.5,\n    fill = 'grey30') +\n  stat_summary(\n    fun.min = function(x) mean(x) - sd(x), \n    fun.max = function(x) mean(x) + sd(x), \n    geom = \"errorbar\", \n    width = 0.2,\n    position = position_dodge(0.3),\n    colour = 'grey30',\n    alpha = 0.75) +\n  labs(y='log2 FC to Group 1')+\n  theme_minimal() +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nlog2 FC of absorbance Values to Group 1\n\n\n\n\n\n\n\nlog2 FC of absorbance Values to Group 1 after subtracting the blank reading\n\n\n\n\n\n*Subtracting “blank” readings\nLet’s look at the values:\n\n\n\n\n\n\nGroup\nFC mean\nFC SD\nFC mean bg sub\nFC SD bg sub\n\n\n\n\nGroup1\n1.0000000\n0.0000000\n1.0000000\n0.0000000\n\n\nGroup2\n0.9572578\n0.1358355\n0.9540441\n0.1517452\n\n\nGroup3\n1.1390257\n0.1739156\n1.1571155\n0.1978752\n\n\nGroup4\n1.3650254\n0.2450446\n1.4093741\n0.2831416\n\n\n\n\n\n\n\n\nGroup 1 (reference “control” group):\n\nBefore and after blank subtraction, the mean fold change remains exactly 1, with zero variance.\n\nThis confirms that normalisation was performed correctly.\n\nGroups 2-4:\n\nThe mean fold changes are very similar before and after blank subtraction.\n\nStandard deviations change slightly.\n\nIf the blank values were significantly contributing to absorbance variation, we would expect a larger shift in mean values and a reduction in standard deviations after subtraction.\n\nHere, the changes are small, suggesting that the blank readings did not introduce much noise in this example dataset.\nShould we subtract the blank?\n\nIf blank values are consistent and small, subtraction may not be necessary as it makes little difference.\n\nIf blanks show high variability, subtraction is essential to remove systematic errors.\n\nA good approach is to check both to see robustness.\n\n\n\n\n\n\n\nRaw data\n\nDoes it fall within expected range of the assay (linear range)?\nAre there outliers? - If yes, deal with them appropriately.\n\nIs blank subtraction necessary?\n\nIt depends.\nIf in doubt, try both.\n\nNormalisation choice:\n\nAlways normalise to a control that is expected to remain stable.\nNormalisation should reduce systematic technical noise while maintaining the true biological differences between groups.\n\nVisual Inspection:\n\nAlways plot raw, corrected, and normalized data to catch inconsistencies."
  },
  {
    "objectID": "colourimetric.html#setup",
    "href": "colourimetric.html#setup",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "First, load the necessary libraries.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "colourimetric.html#raw-data-and-quality-control",
    "href": "colourimetric.html#raw-data-and-quality-control",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "Load the raw data:\n\ncolourimetric_df &lt;- read.csv(\"example_data/colorimetric_example_tidy.csv\")\n\nglimpse(colourimetric_df)\n\nRows: 45\nColumns: 4\n$ Experiment &lt;chr&gt; \"Exp1\", \"Exp1\", \"Exp1\", \"Exp1\", \"Exp1\", \"Exp1\", \"Exp1\", \"Ex…\n$ Group      &lt;chr&gt; \"Group1\", \"Group1\", \"Group1\", \"Group2\", \"Group2\", \"Group2\",…\n$ Replicate  &lt;int&gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2,…\n$ Absorbance &lt;dbl&gt; 0.6790, 0.6650, 0.6560, 0.5430, 0.5380, 0.5830, 0.7560, 0.7…\n\n\nThe example data set are absorbance values, the raw values from the plate reader. This example data set contains data for three different experiments, four treatment groups. For each experiment and each group there are three technical replicates (pipetting replicates). There is also three “blank” measurements for each group, that is the assay buffer without a sample. A “blank” is a control that contains all assay components except the analyte of interest (e.g. the buffer but no cells), used to measure background absorbance and correct for non-specific signal.\n\n\n\nsummary(colourimetric_df)\n\n  Experiment           Group             Replicate   Absorbance    \n Length:45          Length:45          Min.   :1   Min.   :0.0615  \n Class :character   Class :character   1st Qu.:1   1st Qu.:0.5380  \n Mode  :character   Mode  :character   Median :2   Median :0.6790  \n                                       Mean   :2   Mean   :0.5694  \n                                       3rd Qu.:3   3rd Qu.:0.7450  \n                                       Max.   :3   Max.   :0.9170  \n\n\nAny missing values should be examined to determine if they result from experimental errors. There are no missing values in the example data.\n\n\n\nTo see the distribution of absorbance values across different groups and experiments, plot:\n\nylimit &lt;- max(colourimetric_df$Absorbance)*1.1 # use the max absorbance value for upper y limit\nggplot(colourimetric_df, aes(x=Group, y=Absorbance, colour=Experiment, shape=as.factor(Replicate))) +\n  geom_point(position = position_dodge(0.5), alpha = 0.75, size = 2) +\n  stat_summary(aes(group = Experiment),\n               fun = mean,\n               fun.min = function(x) mean(x) - sd(x),\n               fun.max = function(x) mean(x) + sd(x),\n               geom = \"pointrange\", size = 1, shape = 18,\n               colour = 'darkgrey', alpha = 0.75,\n               position = position_dodge(0.3)) +\n  labs(color = 'Experiment', shape = 'Replicate', x=\"\") +\n  scale_y_continuous(limits = c(0, ylimit))+\n  theme_minimal(base_size = 12) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\nGraphing one point for each data point, using colours and shapes to distinguish between the experiments and the technical replicates. QC check: data falls within the linear range of the assay (in the example the linear range is between 0.1 and 1). However, there is one value certainly “off”."
  },
  {
    "objectID": "colourimetric.html#handling-outliers-and-exclusions",
    "href": "colourimetric.html#handling-outliers-and-exclusions",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "In the graph above, we can see that Experiment 1, Group 3, Replicate 3 has an absorbance value similar to the blank readings. We have to determine if this is a real reading or if data collection errors such as pipetting mistakes have occurred. In the example, we confirm with our “lab notes” that this well might not have been properly pipetted, and we exclude it:\n\ncolourimetric_df &lt;- colourimetric_df %&gt;% \n  filter(!(Experiment == \"Exp1\" & Group == \"Group3\" & Replicate == 3))\n\nWe replot the data:\n\nylimit &lt;- max(colourimetric_df$Absorbance)*1.1 # use the max absorbance value for upper y limit\nggplot(colourimetric_df, aes(x=Group, y=Absorbance, colour=Experiment, shape=as.factor(Replicate))) +\n  geom_point(position = position_dodge(0.5), alpha = 0.75, size = 2) +\n  stat_summary(aes(group = Experiment),\n               fun = mean,\n               fun.min = function(x) mean(x) - sd(x),\n               fun.max = function(x) mean(x) + sd(x),\n               geom = \"pointrange\", size = 1, shape = 18,\n               colour = 'darkgrey', alpha = 0.75,\n               position = position_dodge(0.3)) +\n  labs(color = 'Experiment', shape = 'Replicate', x=\"\") +\n  scale_y_continuous(limits = c(0, ylimit))+\n  theme_minimal(base_size = 12) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\nand we see that the exclusion worked as expected. This outlier is removed based on documented lab notes confirming a technical issue. Excluding data without a valid reason is cherry-picking and is not scientifically sound."
  },
  {
    "objectID": "colourimetric.html#background-correction-subtracting-blank-values",
    "href": "colourimetric.html#background-correction-subtracting-blank-values",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "It depends.\n\nIf you are interested in absolute absorbance values - yes.\nIf there is significant background noise and it is also different between the plates (experiments), it can better to subtract the mean blank value per experiment to correct for plate inconsistencies. However, if you see inconsistencies between plates that you wouldn’t expect, (there is no technical reason for it), you should check your experimental set-up.\nIf the blank values are consistently low, there is minimal drift, and you are interested in relative comparisons between groups (or interpolating agains standard curve), subtraction may not be necessary.\n\nFor the example, we can try both:\n\nblank_means &lt;- colourimetric_df %&gt;%\n  filter(Group == \"Blank\") %&gt;%\n  group_by(Experiment) %&gt;%\n  summarise(BlankMean = mean(Absorbance))\n\ncolourimetric_df &lt;- colourimetric_df %&gt;%\n  left_join(blank_means, by = \"Experiment\") %&gt;%\n  mutate(Absorbance_Corrected = Absorbance - BlankMean) %&gt;%\n  filter(Group != \"Blank\")  # Remove blank values now that we have subtracted"
  },
  {
    "objectID": "colourimetric.html#averaging-technical-replicates",
    "href": "colourimetric.html#averaging-technical-replicates",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "Each experiment contains technical replicates, which we average to obtain a single value per group per experiment. As we try with and without subtracting the blank reading, we average both.\n\ncolourimetric_df_meantechnical &lt;- colourimetric_df %&gt;%  \n  group_by(Experiment, Group) %&gt;%\n  summarise(AbsorbanceMeanCorrected = mean(Absorbance_Corrected),\n            AbsorbanceSDCorrected = sd(Absorbance_Corrected),\n            AbsorbanceMean = mean(Absorbance),\n            AbsorbanceSD = sd(Absorbance)\n            )"
  },
  {
    "objectID": "colourimetric.html#normalisation",
    "href": "colourimetric.html#normalisation",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "To compare across experiments, we normalise all values relative to the control group (Group 1) within each experiment: As we try with and without subtracting the blank reading, we do it for both.\n\ncolourimetric_df_Normalised &lt;- colourimetric_df_meantechnical %&gt;%  \n  group_by(Experiment) %&gt;%\n  mutate(Normalised = AbsorbanceMean / AbsorbanceMean[Group == 'Group1'],\n         NormalisedCorrected = AbsorbanceMeanCorrected / AbsorbanceMeanCorrected[Group == 'Group1'])"
  },
  {
    "objectID": "colourimetric.html#summarising-across-biological-replicates",
    "href": "colourimetric.html#summarising-across-biological-replicates",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "To report results, we show the data point for each biological replicate as well as the mean and standard deviation.\nylimit &lt;- max(colourimetric_df_Normalised$Normalised)*1.1\nggplot(colourimetric_df_Normalised, aes(x=Group, y=Normalised)) +\n  geom_jitter(height = 0, alpha = 0.75, size = 2) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\", \n    position = position_dodge(0.3), \n    width = 0.6,\n    alpha = 0.5,\n    fill = 'grey30') +\n  stat_summary(\n    fun.min = function(x) mean(x) - sd(x), \n    fun.max = function(x) mean(x) + sd(x), \n    geom = \"errorbar\", \n    width = 0.2,\n    position = position_dodge(0.3),\n    colour = 'grey30',\n    alpha = 0.75) +\n  scale_y_continuous(limits = c(0, ylimit))+\n  labs(y='FC to Group 1', x=\"\")+\n  theme_minimal(base_size = 12) +\n  theme(legend.position = 'bottom')\n#ylimit &lt;- max(colourimetric_df_Normalised$NormalisedCorrected)*1.1\nggplot(colourimetric_df_Normalised, aes(x=Group, y=NormalisedCorrected)) +\n  geom_jitter(height = 0, alpha = 0.75, size = 2) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\", \n    position = position_dodge(0.3), \n    width = 0.6,\n    alpha = 0.5,\n    fill = 'grey30') +\n  stat_summary(\n    fun.min = function(x) mean(x) - sd(x), \n    fun.max = function(x) mean(x) + sd(x), \n    geom = \"errorbar\", \n    width = 0.2,\n    position = position_dodge(0.3),\n    colour = 'grey30',\n    alpha = 0.75) +\n  scale_y_continuous(limits = c(0, ylimit))+\n  labs(y='FC to Group 1',  x=\"\")+\n  theme_minimal(base_size = 12) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nAbsorbance value fold change (FC) to Group 1\n\n\n\n\n\n\n\nAbsorbance value fold change (FC) to Group 1 after subtracting the blank reading\n\n\n\n\n\nThe graph above displays the fold change relative to Group 1. Key observations: - Since Group 1 is the normalisation reference for each experiment, the mean value is always 1, and the standard deviation is 0, - When fold changes are less than 1, a standard y-axis can be misleading. Consider using a log2 transformation for clearer visualisation.\nggplot(colourimetric_df_Normalised, aes(x=Group, y=log2(Normalised))) +\n  geom_jitter(height = 0, alpha = 0.75, size = 2) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\", \n    position = position_dodge(0.3), \n    width = 0.6,\n    alpha = 0.5,\n    fill = 'grey30') +\n  stat_summary(\n    fun.min = function(x) mean(x) - sd(x), \n    fun.max = function(x) mean(x) + sd(x), \n    geom = \"errorbar\", \n    width = 0.2,\n    position = position_dodge(0.3),\n    colour = 'grey30',\n    alpha = 0.75) +\n  labs(y='log2 FC to Group 1')+\n  theme_minimal() +\n  theme(legend.position = 'bottom')\nylimit &lt;- max(colourimetric_df_Normalised$AbsorbanceMeanCorrected)*1.1\nggplot(colourimetric_df_Normalised, aes(x=Group, y=log2(NormalisedCorrected))) +\n  geom_jitter(height = 0, alpha = 0.75, size = 2) +\n  stat_summary(\n    fun = mean,\n    geom = \"bar\", \n    position = position_dodge(0.3), \n    width = 0.6,\n    alpha = 0.5,\n    fill = 'grey30') +\n  stat_summary(\n    fun.min = function(x) mean(x) - sd(x), \n    fun.max = function(x) mean(x) + sd(x), \n    geom = \"errorbar\", \n    width = 0.2,\n    position = position_dodge(0.3),\n    colour = 'grey30',\n    alpha = 0.75) +\n  labs(y='log2 FC to Group 1')+\n  theme_minimal() +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nlog2 FC of absorbance Values to Group 1\n\n\n\n\n\n\n\nlog2 FC of absorbance Values to Group 1 after subtracting the blank reading\n\n\n\n\n\n*Subtracting “blank” readings\nLet’s look at the values:\n\n\n\n\n\n\nGroup\nFC mean\nFC SD\nFC mean bg sub\nFC SD bg sub\n\n\n\n\nGroup1\n1.0000000\n0.0000000\n1.0000000\n0.0000000\n\n\nGroup2\n0.9572578\n0.1358355\n0.9540441\n0.1517452\n\n\nGroup3\n1.1390257\n0.1739156\n1.1571155\n0.1978752\n\n\nGroup4\n1.3650254\n0.2450446\n1.4093741\n0.2831416\n\n\n\n\n\n\n\n\nGroup 1 (reference “control” group):\n\nBefore and after blank subtraction, the mean fold change remains exactly 1, with zero variance.\n\nThis confirms that normalisation was performed correctly.\n\nGroups 2-4:\n\nThe mean fold changes are very similar before and after blank subtraction.\n\nStandard deviations change slightly.\n\nIf the blank values were significantly contributing to absorbance variation, we would expect a larger shift in mean values and a reduction in standard deviations after subtraction.\n\nHere, the changes are small, suggesting that the blank readings did not introduce much noise in this example dataset.\nShould we subtract the blank?\n\nIf blank values are consistent and small, subtraction may not be necessary as it makes little difference.\n\nIf blanks show high variability, subtraction is essential to remove systematic errors.\n\nA good approach is to check both to see robustness."
  },
  {
    "objectID": "colourimetric.html#qc-checkpoints-considerations",
    "href": "colourimetric.html#qc-checkpoints-considerations",
    "title": "Colourimetric Data Analysis",
    "section": "",
    "text": "Raw data\n\nDoes it fall within expected range of the assay (linear range)?\nAre there outliers? - If yes, deal with them appropriately.\n\nIs blank subtraction necessary?\n\nIt depends.\nIf in doubt, try both.\n\nNormalisation choice:\n\nAlways normalise to a control that is expected to remain stable.\nNormalisation should reduce systematic technical noise while maintaining the true biological differences between groups.\n\nVisual Inspection:\n\nAlways plot raw, corrected, and normalized data to catch inconsistencies."
  },
  {
    "objectID": "microscopy.html",
    "href": "microscopy.html",
    "title": "Microscopy Data Analysis",
    "section": "",
    "text": "Imaging for Immunofluorescence (IF): the essentials\nGoal:\n\nacquire publishable images where the signal you see actually represents the biology you’re studying, not an artefact of bad microscope settings.\nacquire images that are suitable for image analysis and quantification\n\nPrerequisite: You MUST understand what a digital image is. If you don’t know that an image is a grid of pixels and that each pixel has an intensity value (e.g., 0-4095 for a 12-bit image), visit the\n\nZEISS Webinar on Image Analysis Basics and Practice\nIMB’s Introduction to Image Processing\n\n\nThe First Two Rules of Microscopy:\n\nUnless you understand what a digital image is, the different image types and what a histogram, there is no point in you starting microscopy.\nYour image quality is fundamentally limited by your sample. A garbage stain will give you a garbage image, which will lead to garbage quantification. No amount of microscope expertise can save a poorly prepared or non-optimised sample.\n\n\n\n1. Signal-to-Noise Ratio (SNR)\nBefore you adjust any settings, you need to understand the fundamental quality metric of your image: the Signal-to-Noise Ratio (SNR).\n\nSignal: The actual, specific light emitted from your fluorophore that you are interested in. This is the biological information you want to capture.\nNoise: All the random, unwanted variations in pixel intensity that obscure your signal. This includes:\n\nShot noise: The inherent statistical variation in photon arrival, even from a constant light source.\nRead noise: Electronic noise introduced by the camera sensor when it converts photons into a digital signal.\nBackground: This includes autofluorescence from the sample, non-specific antibody binding, and stray light. It acts as noise that drowns out the specific signal.\n\nSNR: The ratio of your true signal to the total noise. A higher SNR means a cleaner, more trustworthy, and quantifiable image.\n\n\nWhat does it mean in an image?\n\nHigh SNR: Image looks crisp and clean. Features are distinct from the background. You can be confident that bright pixels are real signal and you can accurately measure intensities and shapes.\nLow SNR: Image looks “grainy” or “fuzzy.” It’s hard to tell where the real signal ends and the noise begins. Any quantification from a low-SNR image is garbage. You cannot reliably measure what you cannot clearly distinguish from background.\n\n\n\nEasy way to find it out while at the microscope (The Snapshot Method)\nThis is a quick, qualitative check you can do during acquisition to assess your image health.\n\nTake a ‘snapshot’: Acquire an image with your current settings. On the MICA, this is the “Snapshot” button. In other software, it might be “Acquire,” “Preview,”. You may potentially also be able to see the intensities in “Live.”\nInspect the image: Open the snapshot in the microscope’s results viewer, Fiji, or any software that lets you inspect pixel intensity values (in Arbitrary Units, AU).\nFind your background:\n\nArea background: Move your field of view to an area with no cells. Look at the pixel intensities. This is your baseline Background Noise. It should be low and relatively uniform.\nCellular background (better): Move to a cell that should not have your specific stain (e.g., a DAPI-only channel, or a cell type known to be negative). The intensity here represents your sample’s autofluorescence and non-specific background. This is the most relevant background for SNR.\n\nFind your signal: Look at the pixel intensity values in a brightly stained feature and in a dimmer one.\nAssess mentally:\n\nGood SNR: The intensity of your stained feature is much higher than the cellular background, and the background itself looks smooth, not speckly.\nBad SNR: The stained feature isn’t much brighter than the speckly variations in the background. You have to squint to decide if something is real.\n\n\nA rule of thumb: On an 8-bit scale (0-255), aim for a background intensity in the range of ~10-50 AU and a clear signal well above that, ideally in the ~100-200 AU range for your features of interest. This provides a good dynamic range for quantification while avoiding a background that is too high or a signal that is saturated. This might not always be totally true but gives you a starting point.\n\n\nSNR of Intense vs. Weak Stains\n\nIntensely Stained Features: Easy. The strong signal makes achieving a high SNR straightforward. The primary danger is saturation, where your signal is so intense it maxes out the camera’s dynamic range, destroying information.\nWeakly Stained Features: This is the real challenge. The signal is low and easily drowned out by noise. To improve SNR for weak stains, you must:\n\nIncrease signal: Use longer exposure time or higher laser power.\nReduce noise: Use camera binning or frame averaging (at the cost of resolution or speed).\nAlways check your controls: When you change settings to see a weak stain, you also amplify everything else. You MUST check your negative control with these new, higher settings. If your negative control starts to look bright and speckly, your “signal” is likely just amplified background noise, and your experiment is not specific.\n\n\n\n\n\n\n2. Resolution and Magnification\nDo not confuse magnification (“making things bigger”) with resolution (“seeing things clearly”). Resolution is the ability to distinguish two close objects as separate. While magnification enlarges an image, ultimate resolution is determined by your objective lens and the physics of light (Abbe’s Law).\n\nEmpty magnification (e.g., digitally zooming a low-resolution image) does not reveal new detail.\nA practical check: A feature must span multiple pixels to be quantified. If you are imaging a fiber that is 200 nm thick and your pixel size is 150 nm, the fiber will only be ~1.3 pixels wide, making accurate measurement impossible. Choose your objective and camera settings so your structures are adequately sampled across several pixels.\n\n\n\n\n3. Setting Imaging Settings - Controls cannot be avoided\nYou cannot set your imaging parameters in a vacuum. You need controls to define the boundaries of your settings for quantification.\n\nThe Positive Control\n\nWhat it is: A sample where you are certain your target is strongly expressed and stained well. This confirms your staining protocol worked.\nHow to use it for imaging: The positive control helps you establish a reasonable intensity range, but it may not always set the final upper limit for your experiment. Use it to verify your staining worked and to get in the right exposure ballpark.\nSetting the actual upper limit: You must use the brightest sample in your experimental series to determine your final imaging settings. For example:\n\nIf your in vitro cells have much fainter collagen staining than your tissue positive control, use the brightest in vitro sample to avoid underexposing your actual data.\nIf an experimental group is brighter than your positive control, use that group instead.\n\nThe key principle: Your imaging settings must ensure that the brightest pixel across ALL samples you plan to compare is below saturation. Always check your brightest experimental sample, not just the control. But don’t skip the positive control either, especially when working with new antibodies or protocols.\n\n\n\nThe Negative Control\n\nWhat it is: A sample to define your background. There are different types of negative controls:\n\nBiological Negative: A sample (e.g., a KO, treated, or wild-type cell) known not to express the target. This is the gold standard as it accounts for autofluorescence and non-specific binding in your specific biological context.\nNo Primary Control: A sample processed without the primary antibody. This controls for non-specific binding of your secondary antibody.\nIsotype Control: A sample incubated with a non-specific antibody of the same isotype as your primary. This controls for non-specific Fc receptor binding.\nReal world: In many labs, resource or experimental constraints mean that a full suite of controls for every experiment isn’t always feasible. You might use either a “no primary” or an “isotype” control. While this is common practice, it’s important to understand that each control answers a slightly different question, and their limitations should be acknowledged when interpreting your data. The goal is to use the most appropriate control available to you to confidently distinguish specific signal from background. Moreover, for the biological controls, you may often worked with mixed populations, where you have negative and positive cells in one sample.\n\nHow to use it: Image the negative control with the exact same settings you defined using your positive/experimental samples.\nHow it should look: It should be dark. You might see faint, diffuse cell outlines (autofluorescence), but there should be no specific staining pattern that resembles your real signal. If you see specific-looking speckles or structures, your staining is not specific, and your data is not trustworthy.\n\nThe Workflow: Set exposure on your brightest sample (pos ctrl/brightest experimental group) to avoid saturation. -&gt; Use the Negative Control to verify your signal is specific above background and you didn’t introduce artefacts by increasing the light for a faint staining. -&gt; Apply those exact same settings to all experimental samples\n\n\n\n\n4. Using the Histogram\nThe histogram is the most helpful too! It is a graph showing the number of pixels at each intensity value in your image.\nOf course. Here is the revised “Using the Histogram” section with your edits and a clear explanation of the “real world” scenario.\n\n\n\n4. Using the Histogram\nThe histogram is the most helpful tool! It is a graph showing the number of pixels at each intensity value in your image.\n\nLeft side of graph: Dark pixels (background, black).\nRight side of graph: Bright pixels (signal, white).\nIdeal image:\n\nA sharp, narrow peak on the far left (your background).\nA separate peak or a shoulder further to the right (your specific signal).\nA clear valley between them, indicating good contrast and SNR.\n\nSaturation: A huge spike slammed against the far right wall. This means signal is clipped and data is lost forever. BAD.\nLow SNR: One single thing peak, background and signal blends directly into each other. The image is noisy. BAD.\n“Flashlight in a Fog”: The entire histogram is shifted to the right. The background is too bright, killing your contrast. BAD.\nThe Real World: You will often not get two perfect, separate hills, especially with weak signals. In this case, you will see a single peak that is stretched to the right.\n\nA narrow peak that is centered means your background is low and your signal is also low/absent.\nA broad, right-skewed peak means your signal is present and shifting the pixel intensities to higher values. The broader and more right-shifted this peak is (without hitting the right wall), the stronger your signal and the better your dynamic range. The key is that the leftmost part of the peak should still be close to 0, indicating a dark background.\n\n\n\n\n\n5. Auto Range vs. Full Range (Viewing Lookup Tables - LUTs)\nThis is a CRITICAL distinction. LUTs change how you SEE the image on screen, but they do NOT change the actual acquired data. You can always change the display later, but you cannot recover data lost to bad acquisition settings.\n\nAuto Range (or Scaled): The software automatically stretches the histogram to fill the entire display range. It makes the darkest pixel in your current field of view black and the brightest pixel white.\n\nUse: Excellent for finding your sample quickly.\nDanger: It makes almost every image look like it has perfect contrast, hiding serious problems. A dim, noisy image may look fine. However, it can also dramatically blow up a few background pixels, making a clean sample look noisy. Do not use Auto Range to set your exposure or assess image quality.\n\nFull / Absolute / Manual Range: The display is locked to the full bit-depth of your camera (e.g., 0-4095). What you see is a direct representation of your data.\n\nUse: This is the mode you should use for setting exposure and acquiring data.\nWhy: It allows you to see the true histogram. You can instantly spot if your background is too high (histogram shifted right) or if your signal is saturated (pixels piling up at the max value).\n\n\nThe workflow: 1. FIND YOUR SAMPLE using Auto Range. 2. SWITCH TO MANUAL/ABSOLUTE RANGE. 3. SET YOUR EXPOSURE by adjusting laser power/exposure time while watching the histogram in the Absolute Range view. Aim for a background peak near 0 and a signal that does not touch the right wall.\nYou can always apply a LUT later for a presentation figure, but you can never un-saturate an image or recover lost dynamic range.\n\n\nSummary: A Basic Imaging Checklist\n\n[ ] Understand your image: Bit-depth, pixels, etc.\n[ ] Use controls: Set exposure on your Positive Control to avoid saturation. Confirm low background with your Negative Control.\n[ ] Check the Histogram: Look for saturation and a clean background peak near 0.\n[ ] View in Absolute/Manual Range when setting acquisition settings. Never trust Auto Range for quantification.\n[ ] Assess SNR: Take a mental snapshot of background vs. signal. If it’s grainy, figure out why before proceeding.\n\nFurther Reading: * Microscopy Online Resources - IMB, UQ * ZEISS Image Analysis Basics and Practice"
  }
]